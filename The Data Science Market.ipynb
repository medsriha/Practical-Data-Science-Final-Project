{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<img style=\"width:100%\" src='https://s3.amazonaws.com/dsmcmu/Capture1.JPG'>]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we will be explaining the steps taken to create the back-end of a web application that displays data science-related jobs for analysis purpose. **This project aims to help people who are applying for data science positions in the U.S to have an overlook on the data science jobs trends** to analyze and take further decisions concerning:\n",
    "\n",
    " - Top Data science skills that are in deman on a daily basis.\n",
    " - U.S cities that hires the most data scientists.\n",
    " - Average salary on a daily basis of a data scientist in a specific U.S city.\n",
    " \n",
    "When a user visits the Data Science Market website, he will have access to the top data science skills trends, their movements over a certain period of time, the trends of the U.S cities that hires the most Data Scientists and the flow of their demand over a period of time. Also the access to the average salary of data scientist in some major US cities. With this platform, we believe that anyone who is applying or thinking to apply for a data science job will have a solid estimate about the current scenario and happenings in the data science world and all these informations will help them to decide their strategies like how to formulate their resumes, which cites to apply for a better success ratio in according to the demand of data scientisits as well as what salary to expect based on the current job market.\n",
    " \n",
    "> All data have been scrapped from [Dice](https://www.dice.com/), a very popular career website. Below is the list of scrapped features:\n",
    "- `Employeer`\n",
    "- `company_name`\n",
    "- `date_posted` (The day the job was posted on Dice)\n",
    "- `empl_type`\n",
    "- `job_title`\n",
    "- `location`\n",
    "- `salary`\n",
    "- `skills`\n",
    "\n",
    "\n",
    "> FYI: Data has been scrapped automatically every day at 11 pm. This notebook is about the business logics behind the calculations and the one that we took to build the web application.\n",
    "\n",
    "\n",
    "For every section of this notebook, we will be creating 7 SQL tables stored on a local server (localhost).\n",
    "The structure of the web application is as follows:\n",
    "\n",
    "- For every page, we will be displaying a list of the 40 most frequent skills, cities, and salaries by cities. The three lists will hold the 40 most frequent categories (Skills, Cities, and Salaries).\n",
    "- For every page, we will be displaying a line-chart that shows the frequency of the skills, cities and salaries since we started scrapping the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Screenshots of the Web application.\n",
    "\n",
    "URL of the web application: http://ec2-34-207-60-106.compute-1.amazonaws.com:8080/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<img style=\"width:100%\" src='https://s3.amazonaws.com/dsmcmu/Untitled.png'>]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "\n",
    "**1. [Skills Processing](#1.-Skills-Processing)** \n",
    "    - All Skills.\n",
    "    - 40 most frequent skills.\n",
    "**2. [Cities Processing](#2.-Cities-Processing)**\n",
    "    - All Cities.\n",
    "    - 40 most frequent cities. \n",
    "**3. [Salaries Processing](#3.-Salaries-Processing)**\n",
    "    - All Salaries by cities.\n",
    "    - Most paying cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's first upload the different libraries, there will be no need to download an external package, all the packages are present in the Anaconda environement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import nltk\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "from pandas.io import sql\n",
    "# Package to create a connexion to local MySql server\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After we are done with importing python packages, let us run our first script. \n",
    "- We will be uploading the file using Pandas read_csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>empl_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dex Media</td>\n",
       "      <td>2018-04-22</td>\n",
       "      <td>full-time</td>\n",
       "      <td>Principal Network Engineer</td>\n",
       "      <td>Dfw-airport, TX</td>\n",
       "      <td>Depends On Experience</td>\n",
       "      <td>Architecture, Call Center, CCIE, CCNP, Change ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dex Media</td>\n",
       "      <td>2018-04-22</td>\n",
       "      <td>full-time</td>\n",
       "      <td>Lead Sales Force/Software Engineer</td>\n",
       "      <td>Dfw Airport, TX</td>\n",
       "      <td>Depends On Experience</td>\n",
       "      <td>Android, API, B2B, Development, Graphics, iOS,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cardtronics</td>\n",
       "      <td>2018-04-22</td>\n",
       "      <td>full-time</td>\n",
       "      <td>Cash Install Analyst</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Competitive</td>\n",
       "      <td>Cash Install Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cardtronics</td>\n",
       "      <td>2018-04-22</td>\n",
       "      <td>full-time</td>\n",
       "      <td>Service Delivery Specialist</td>\n",
       "      <td>Frisco, TX</td>\n",
       "      <td>Competitive</td>\n",
       "      <td>Service Delivery Specialist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cardtronics</td>\n",
       "      <td>2018-04-22</td>\n",
       "      <td>full-time</td>\n",
       "      <td>Director of Investigations</td>\n",
       "      <td>Frisco, TX</td>\n",
       "      <td>Competitive</td>\n",
       "      <td>Director of Investigations</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_name date_posted   empl_type                           job_title  \\\n",
       "0    Dex Media  2018-04-22  full-time           Principal Network Engineer   \n",
       "1    Dex Media  2018-04-22  full-time   Lead Sales Force/Software Engineer   \n",
       "2  Cardtronics  2018-04-22  full-time                 Cash Install Analyst   \n",
       "3  Cardtronics  2018-04-22  full-time          Service Delivery Specialist   \n",
       "4  Cardtronics  2018-04-22  full-time           Director of Investigations   \n",
       "\n",
       "          location                 salary  \\\n",
       "0  Dfw-airport, TX  Depends On Experience   \n",
       "1  Dfw Airport, TX  Depends On Experience   \n",
       "2      Houston, TX            Competitive   \n",
       "3       Frisco, TX            Competitive   \n",
       "4       Frisco, TX            Competitive   \n",
       "\n",
       "                                              skills  \n",
       "0  Architecture, Call Center, CCIE, CCNP, Change ...  \n",
       "1  Android, API, B2B, Development, Graphics, iOS,...  \n",
       "2                               Cash Install Analyst  \n",
       "3                        Service Delivery Specialist  \n",
       "4                         Director of Investigations  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('Dice Back up.xlsx')\n",
    "#Output of the data file.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Next, we will be downloading the NLTK sub packages which comes with many corpora, toy grammars, trained models, etc. This project requires NLTK's stopwords list and WordNetLemmatizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\medSr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\medSr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\medSr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Skills Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the first section, we will be processing and cleaning the data which belong to the skills column. \n",
    "Before any move, we will split the file into an array of n dataframes; n represents the number of days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    indices = []\n",
    "    i = 1\n",
    "    indices.append(0)\n",
    "    while i < len(data):\n",
    "        if data['date_posted'].iloc[i] > data['date_posted'].iloc[i - 1]:\n",
    "            indices.append(i)\n",
    "        i+=1\n",
    "    indices.append(i)\n",
    "    return [data[a:b].set_index('date_posted') for (a,b) in zip(indices[:-1], indices[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>empl_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_posted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-22</th>\n",
       "      <td>Dex Media</td>\n",
       "      <td>full-time</td>\n",
       "      <td>Principal Network Engineer</td>\n",
       "      <td>Dfw-airport, TX</td>\n",
       "      <td>Depends On Experience</td>\n",
       "      <td>Architecture, Call Center, CCIE, CCNP, Change ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-22</th>\n",
       "      <td>Dex Media</td>\n",
       "      <td>full-time</td>\n",
       "      <td>Lead Sales Force/Software Engineer</td>\n",
       "      <td>Dfw Airport, TX</td>\n",
       "      <td>Depends On Experience</td>\n",
       "      <td>Android, API, B2B, Development, Graphics, iOS,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-22</th>\n",
       "      <td>Cardtronics</td>\n",
       "      <td>full-time</td>\n",
       "      <td>Cash Install Analyst</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Competitive</td>\n",
       "      <td>Cash Install Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-22</th>\n",
       "      <td>Cardtronics</td>\n",
       "      <td>full-time</td>\n",
       "      <td>Service Delivery Specialist</td>\n",
       "      <td>Frisco, TX</td>\n",
       "      <td>Competitive</td>\n",
       "      <td>Service Delivery Specialist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-22</th>\n",
       "      <td>Cardtronics</td>\n",
       "      <td>full-time</td>\n",
       "      <td>Director of Investigations</td>\n",
       "      <td>Frisco, TX</td>\n",
       "      <td>Competitive</td>\n",
       "      <td>Director of Investigations</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            company_name   empl_type                           job_title  \\\n",
       "date_posted                                                                \n",
       "2018-04-22     Dex Media  full-time           Principal Network Engineer   \n",
       "2018-04-22     Dex Media  full-time   Lead Sales Force/Software Engineer   \n",
       "2018-04-22   Cardtronics  full-time                 Cash Install Analyst   \n",
       "2018-04-22   Cardtronics  full-time          Service Delivery Specialist   \n",
       "2018-04-22   Cardtronics  full-time           Director of Investigations   \n",
       "\n",
       "                    location                 salary  \\\n",
       "date_posted                                           \n",
       "2018-04-22   Dfw-airport, TX  Depends On Experience   \n",
       "2018-04-22   Dfw Airport, TX  Depends On Experience   \n",
       "2018-04-22       Houston, TX            Competitive   \n",
       "2018-04-22        Frisco, TX            Competitive   \n",
       "2018-04-22        Frisco, TX            Competitive   \n",
       "\n",
       "                                                        skills  \n",
       "date_posted                                                     \n",
       "2018-04-22   Architecture, Call Center, CCIE, CCNP, Change ...  \n",
       "2018-04-22   Android, API, B2B, Development, Graphics, iOS,...  \n",
       "2018-04-22                                Cash Install Analyst  \n",
       "2018-04-22                         Service Delivery Specialist  \n",
       "2018-04-22                          Director of Investigations  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = split_data(data)\n",
    "#let's display the Dataframe from the first day\n",
    "split[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After we split our file into several dataframes, we will then start processing and cleaning the data. Because the data was scraped from [Dice](https://www.dice.com/) and entered manually by recruiters, we have noticed that some cleaning is needed. such as eliminating unnecessary punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skills text processing\n",
    "def cleaning(text,lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    punctuation = set(re.findall(r\"[^\\w\\s]+\", \" \".join(text))) - {','}\n",
    "    #Replace punctuation by a space\n",
    "    for c in punctuation:\n",
    "        if c in text:\n",
    "            text = text.replace(c, ' ')\n",
    "    #Some rows are not data seperate by comma.\n",
    "    if ',' not in text:\n",
    "        text = text.replace(' ', ',')\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the above function on the 'Skills' column\n",
    "list_process = []\n",
    "for i in range(len(split)):\n",
    "    arr = []\n",
    "    for j in split[i]['skills']:\n",
    "        processing = cleaning(j)\n",
    "        arr.append(processing)\n",
    "    list_process.append(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Second function is to calculate the frequency of each skills as a word in a single day. This why we split the data at first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word frequency\n",
    "def tfidf_skills(data):\n",
    "    all_words = {doc for doc in data}\n",
    "    wordIndexDict = {word:i for i,word in enumerate(list(all_words))}\n",
    "    \n",
    "    number_word = 0\n",
    "    docWordCounts = {}\n",
    "    for i,doc in enumerate(data):\n",
    "        doc = str(doc)\n",
    "        words = doc.split(', ')\n",
    "        counts = Counter(words)\n",
    "        \n",
    "        docWordCounts[i] = dict(counts)\n",
    "    df = {}\n",
    "\n",
    "    for doc, wordCountDict in docWordCounts.items():\n",
    "        for word in wordCountDict.keys():\n",
    "            if word in df:\n",
    "                df[word] += 1\n",
    "            else:\n",
    "                df[word] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have also noticed that some words have typos and tends to be very low in frequency, so we have decided to delete them with the help of a function mentioned below. Basically filtering words that have a frequency of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_rare_words(data):\n",
    "    words = []\n",
    "    for i in data.items():\n",
    "        if i[1] > 2:\n",
    "            words.append(i)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skills_tfidf = [tfidf_skills(list_process[i])for i in range(len(list_process))]\n",
    "delete_words = [delete_rare_words(skills_tfidf[i])for i in range(len(split))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After we cleaned the skills column from unwanted characters and delete the rare words, we will change the format of the output into n dataframes which holds only the skills and their dates where n is the total number of days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = []\n",
    "for i in range(len(split)):\n",
    "    d={ 'skill': delete_words[i],'date':split[i].first_valid_index().date()}\n",
    "    array.append(pd.DataFrame(data=d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate the word and their frequencies\n",
    "for i in array:\n",
    "    i[['skill','frequency']] = i['skill'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unnecessary skills. A bag of words of skills that don't directly mean or define a data scientist skill.\n",
    "unecessary_skills = ['project','manager','developer','analyst','management',\n",
    "              'networking','see,job,description','laptop','software engineer',\n",
    "              'applications','application','project manager','recruiter','director',\n",
    "             'accounting','data analysis','engineering','analytical skills']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will be deleting unnecessary skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(array)):\n",
    "    for j in range(len(unecessary_skills)):\n",
    "        array[i] = array[i][array[i]['skill']!= unecessary_skills[j]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's sort the dataframes by the number of frequencies and drop empty columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(array)):\n",
    "    array[i] = array[i].sort_values(by=['frequency'],ascending=False).reset_index()\n",
    "    array[i] = array[i].dropna()\n",
    "    array[i] = array[i].drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>skill</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-04-22</td>\n",
       "      <td>development</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-04-22</td>\n",
       "      <td>security</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-22</td>\n",
       "      <td>analysis</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-22</td>\n",
       "      <td>testing</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-22</td>\n",
       "      <td>sql</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        skill  frequency\n",
       "0  2018-04-22  development        343\n",
       "1  2018-04-22     security        223\n",
       "2  2018-04-22     analysis        175\n",
       "3  2018-04-22      testing        163\n",
       "4  2018-04-22          sql        150"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#day-one dataframe after sorting\n",
    "array[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this function, we will be calculating the weight of each skill compared to the other skills so we can differentiate between the most and the least demanded skills, and calculate their ups and downs over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weight(data):\n",
    "    data_copy = data.copy()\n",
    "    for i in range(len(data_copy)):\n",
    "        sum_tfidf = data_copy[i]['frequency'].sum()\n",
    "        arr = []\n",
    "        for j in range(len(data_copy[i])):\n",
    "            weight = data_copy[i].iloc[j]['frequency'] / sum_tfidf\n",
    "            arr.append(weight)\n",
    "        data_copy[i]['weight'] = arr\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_skills = calculate_weight(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After calculating the weight for every skill, we will concatenate the array and append the result into a single dataframe. \n",
    "- The reason of the concatenation is that we want to store the dataframe into a MySql server so whenever a user needs an information about a specific skill, all information about that skill will be displayed into a chart-line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_array_skills = pd.concat(weight_skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All skills:\n",
    "- In this section, we will create a connection with the local MySql server using the root username and the local host.\n",
    "- Adding the above-concatenated table to the database will allow us to access all the data (Date, frequencies, and weight) that we need while displaying the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+mysqldb://root:98456292@127.0.0.1/dice\")\n",
    "#Sort by date for an ascending display in the chart-line\n",
    "concat_to_db = concat_array_skills.sort_values(by='date')\n",
    "concat_to_db = concat_to_db.reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's now add the concatenated table into MySql using Pandas to_sql function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\medSr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\default.py:507: Warning: (3719, \"'utf8' is currently an alias for the character set UTF8MB3, which will be replaced by UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.\")\n",
      "  cursor.execute(statement, parameters)\n"
     ]
    }
   ],
   "source": [
    "concat_to_db.to_sql('all_skills_table', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 40 most frequent skills:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After we concatenated all the skills together in a single dataframe, now we will go deeper and filter the skills by their frequencies.\n",
    "- We will group the concatenated dataframe by the skill column.\n",
    "- This section is meant to display to the user an updated list of the most in demand data science skills in the market. You may check the above screenshot to see what the list will look like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_skills = concat_to_db.groupby('skill').sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, we will be calculating the average weight of each skill not by day as we did above, but the average weight for each skill compared to all the skills present in the dataframe.\n",
    "- With this method, we want to know which skill has the largest precentage within the sum of the weight to create a constant skill ranking.\n",
    "- For example, if a specific skill loose frequency in a specific day, it does not mean that this skill will see its ranking drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_sum = grouped_skills['weight'].sum()\n",
    "average_list=[]\n",
    "for i in range(len(grouped_skills)):\n",
    "    average_list.append(grouped_skills.iloc[i]['weight'] / weight_sum)\n",
    "grouped_skills['average_weight'] = average_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We dont need the weight and frequency any more. The average weight is enough for later computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_skills = grouped_skills.reset_index().drop(['weight','frequency'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To be able to see and display the trends, we need to retrieve today's and yesterday's data. \n",
    "- The reason is that we want to display to the user the behavior of a particular skills in a single day. **(i.e, Today, the skill JAVA has dropped by a certain frequency compared to yesterday)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>skill</th>\n",
       "      <th>frequency_yesterday</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>development</td>\n",
       "      <td>319</td>\n",
       "      <td>0.049198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>testing</td>\n",
       "      <td>183</td>\n",
       "      <td>0.028223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>security</td>\n",
       "      <td>181</td>\n",
       "      <td>0.027915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>systems</td>\n",
       "      <td>180</td>\n",
       "      <td>0.027761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>analysis</td>\n",
       "      <td>164</td>\n",
       "      <td>0.025293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        skill  frequency_yesterday    weight\n",
       "0  2018-05-08  development                  319  0.049198\n",
       "1  2018-05-08      testing                  183  0.028223\n",
       "2  2018-05-08     security                  181  0.027915\n",
       "3  2018-05-08      systems                  180  0.027761\n",
       "4  2018-05-08     analysis                  164  0.025293"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yesterday = weight_skills[len(weight_skills)-2]\n",
    "df_yesterday = df_yesterday.rename(columns={'frequency':'frequency_yesterday'})\n",
    "df_yesterday.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>skill</th>\n",
       "      <th>frequency_today</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>development</td>\n",
       "      <td>136</td>\n",
       "      <td>0.055038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>security</td>\n",
       "      <td>118</td>\n",
       "      <td>0.047754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>testing</td>\n",
       "      <td>101</td>\n",
       "      <td>0.040874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>http</td>\n",
       "      <td>85</td>\n",
       "      <td>0.034399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>analysis</td>\n",
       "      <td>83</td>\n",
       "      <td>0.033590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        skill  frequency_today    weight\n",
       "0  2018-05-09  development              136  0.055038\n",
       "1  2018-05-09     security              118  0.047754\n",
       "2  2018-05-09      testing              101  0.040874\n",
       "3  2018-05-09         http               85  0.034399\n",
       "4  2018-05-09     analysis               83  0.033590"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_today = weight_skills[len(weight_skills)-1]\n",
    "df_today = df_today.rename(columns={'frequency':'frequency_today'})\n",
    "df_today.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's merge the today's and yestarday's dataframe together so we can compute the daily weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_x</th>\n",
       "      <th>skill</th>\n",
       "      <th>frequency_today</th>\n",
       "      <th>weight_x</th>\n",
       "      <th>date_y</th>\n",
       "      <th>frequency_yesterday</th>\n",
       "      <th>weight_y</th>\n",
       "      <th>index</th>\n",
       "      <th>average_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>development</td>\n",
       "      <td>136</td>\n",
       "      <td>0.055038</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>319.0</td>\n",
       "      <td>0.049198</td>\n",
       "      <td>263</td>\n",
       "      <td>0.059224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>security</td>\n",
       "      <td>118</td>\n",
       "      <td>0.047754</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.027915</td>\n",
       "      <td>687</td>\n",
       "      <td>0.029391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>testing</td>\n",
       "      <td>101</td>\n",
       "      <td>0.040874</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.028223</td>\n",
       "      <td>801</td>\n",
       "      <td>0.031357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>http</td>\n",
       "      <td>85</td>\n",
       "      <td>0.034399</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.011258</td>\n",
       "      <td>371</td>\n",
       "      <td>0.018821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>analysis</td>\n",
       "      <td>83</td>\n",
       "      <td>0.033590</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.025293</td>\n",
       "      <td>39</td>\n",
       "      <td>0.026978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_x        skill  frequency_today  weight_x      date_y  \\\n",
       "0  2018-05-09  development              136  0.055038  2018-05-08   \n",
       "1  2018-05-09     security              118  0.047754  2018-05-08   \n",
       "2  2018-05-09      testing              101  0.040874  2018-05-08   \n",
       "3  2018-05-09         http               85  0.034399  2018-05-08   \n",
       "4  2018-05-09     analysis               83  0.033590  2018-05-08   \n",
       "\n",
       "   frequency_yesterday  weight_y  index  average_weight  \n",
       "0                319.0  0.049198    263        0.059224  \n",
       "1                181.0  0.027915    687        0.029391  \n",
       "2                183.0  0.028223    801        0.031357  \n",
       "3                 73.0  0.011258    371        0.018821  \n",
       "4                164.0  0.025293     39        0.026978  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_today = df_today.merge(df_yesterday, on='skill',how='left')\n",
    "# merge the today_yesterday dataframe with all the skills dataframe so \n",
    "#we can access the data for the 40 most frequent skills\n",
    "merged = merged_today.merge(grouped_skills, on='skill', how='left')\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After we merge all skill dataframe, today's dataframe and yesterday's dataframe, we will sort the final table by average weight and drop the empty rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the dataframe by average weight so later we can just keep the 40 most frequent skills\n",
    "merged = merged.sort_values(by='average_weight', ascending=False)\n",
    "merged = merged.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the columns for better dislay in the DB server\n",
    "merged = merged.rename(columns={'date_x':'date_today', 'weight_x':'weight_today','weight_y':\n",
    "                                            'weight_yesterday','date_y':'date_yesterday'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the line of code below, we will be calculating the difference between today's and yesterday's frequency.\n",
    "- If a skill has lost a frequency today, we will be displaying to the user a red narrow-down icon, and a green-up icon if it gained a frequency today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['today_trend'] = merged['weight_today'] - merged['weight_yesterday']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No need of frequencies after we calculated the trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.drop(['frequency_today','frequency_yesterday'],axis=1)\n",
    "# merged_today = merged_today[merged_today['word']!='nan']\n",
    "merged['today_trend'] = round(merged['today_trend'],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\medSr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(merged)):\n",
    "    if merged['today_trend'].iloc[i] == -0:\n",
    "        merged['today_trend'].iloc[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the 40 most frequent skills in MySql server\n",
    "merged = merged.reset_index()\n",
    "merged= merged.drop(['index','level_0'],axis=1)\n",
    "# Append to MySQl\n",
    "merged[:39].to_sql('today_trend_skills', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here is the snippet of the list that the user will be seeing. \n",
    "- When the user clicks on a skill from this list, a char-line of the same skill will be displayed from the data stored in \"all list\" table showing the frequency of the skill over a specific period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_today</th>\n",
       "      <th>skill</th>\n",
       "      <th>weight_today</th>\n",
       "      <th>date_yesterday</th>\n",
       "      <th>weight_yesterday</th>\n",
       "      <th>average_weight</th>\n",
       "      <th>today_trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>development</td>\n",
       "      <td>0.055038</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>0.049198</td>\n",
       "      <td>0.059224</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>testing</td>\n",
       "      <td>0.040874</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>0.028223</td>\n",
       "      <td>0.031357</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>security</td>\n",
       "      <td>0.047754</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>0.027915</td>\n",
       "      <td>0.029391</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.033590</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>0.025293</td>\n",
       "      <td>0.026978</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>research</td>\n",
       "      <td>0.029947</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.022323</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_today        skill  weight_today date_yesterday  weight_yesterday  \\\n",
       "0  2018-05-09  development      0.055038     2018-05-08          0.049198   \n",
       "1  2018-05-09      testing      0.040874     2018-05-08          0.028223   \n",
       "2  2018-05-09     security      0.047754     2018-05-08          0.027915   \n",
       "3  2018-05-09     analysis      0.033590     2018-05-08          0.025293   \n",
       "4  2018-05-09     research      0.029947     2018-05-08          0.010179   \n",
       "\n",
       "   average_weight  today_trend  \n",
       "0        0.059224        0.006  \n",
       "1        0.031357        0.013  \n",
       "2        0.029391        0.020  \n",
       "3        0.026978        0.008  \n",
       "4        0.022323        0.020  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged[:39].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cities Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This section is meant to follow the same process as we did with the skills section. First, we will clean the data, then concatenate and save the output into a single dataframe, and finally, keep only the 40 most frequent locations/cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_location = []\n",
    "for i in range(len(split)):\n",
    "    arr = []\n",
    "    # 'Split' is the ouput list from the above function which allowed us to split the dataframe\n",
    "    #into n dataframe according to the number of days.\n",
    "    for j in split[i]['location']:\n",
    "        processing_location = cleaning(j)\n",
    "        arr.append(processing_location)\n",
    "    list_location.append(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The function below will calculate the tfidf or frequency of a location among all the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location frequency counter\n",
    "def tfidf_location(data):\n",
    "    docWordCounts= dict(Counter(data))\n",
    "    df = {}\n",
    "    for doc, wordCountDict in docWordCounts.items():\n",
    "\n",
    "        df[doc] = wordCountDict\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_tfidf_location = [tfidf_location(list_location[i])for i in range(len(list_location))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After we cleaned the location column from unwanted characters and calculated the frequency, we will change the format of the output into n dataframes which holds only the skills and their dates where n is the total number of days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for i in range(len(split)):\n",
    "    d={ 'frequency': skills_tfidf_location[i],'date':split[i].first_valid_index().date()}\n",
    "    df_list.append(pd.DataFrame(data=d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Last polishing before further maneuvers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_list)):\n",
    "    df_list[i] = df_list[i].sort_values(by=['frequency'],ascending=False).reset_index()\n",
    "    df_list[i] = df_list[i].dropna()\n",
    "    df_list [i] = df_list[i].rename(columns={'index':'location'})\n",
    "    #Keep on the cities that have a frequency greater than 1\n",
    "    df_list[i] = df_list[i][df_list[i]['frequency']>1]\n",
    "    #delete empty values which have not be dropped with dropna function\n",
    "    df_list[i]  = df_list[i] [df_list[i] ['location'] !='']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Weight calculation. Same as we did in the skills section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_location = calculate_weight (df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All locations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will be concatenating the list int a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_location = pd.concat(weight_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_location = concat_location.sort_values(by='date', ascending=True)\n",
    "concat_location_db = concat_location.reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add the concatenated table into the DB server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_location_db.to_sql('all_location_table', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>frequency</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>charlotte, nc</td>\n",
       "      <td>2018-04-22</td>\n",
       "      <td>113</td>\n",
       "      <td>0.246187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dfw airport, tx</td>\n",
       "      <td>2018-04-22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>denver, co</td>\n",
       "      <td>2018-04-22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>houston, tx</td>\n",
       "      <td>2018-04-22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>irwindale, ca</td>\n",
       "      <td>2018-04-22</td>\n",
       "      <td>2</td>\n",
       "      <td>0.004357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          location        date  frequency    weight\n",
       "0    charlotte, nc  2018-04-22        113  0.246187\n",
       "1  dfw airport, tx  2018-04-22          2  0.004357\n",
       "2       denver, co  2018-04-22          2  0.004357\n",
       "3      houston, tx  2018-04-22          2  0.004357\n",
       "4    irwindale, ca  2018-04-22          2  0.004357"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_location_db.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 40 most frequent locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_location = concat_location.groupby('location').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_weight = grouped_location['weight'].sum()\n",
    "arr=[]\n",
    "for i in range(len(grouped_location)):\n",
    "    arr.append(grouped_location.iloc[i]['weight'] / sum_weight)\n",
    "grouped_location['average_weight'] = arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We dont need the weight and frequency any more. The average weight is enough for later computation\n",
    "grouped_location = grouped_location.reset_index().drop(['weight','frequency'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>frequency_yesterday</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>42</td>\n",
       "      <td>0.051220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>charlotte, nc</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>34</td>\n",
       "      <td>0.041463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>austin, tx</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>25</td>\n",
       "      <td>0.030488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atlanta, ga</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>23</td>\n",
       "      <td>0.028049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chicago, il</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>19</td>\n",
       "      <td>0.023171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        location        date  frequency_yesterday    weight\n",
       "0   new york, ny  2018-05-08                   42  0.051220\n",
       "1  charlotte, nc  2018-05-08                   34  0.041463\n",
       "2     austin, tx  2018-05-08                   25  0.030488\n",
       "3    atlanta, ga  2018-05-08                   23  0.028049\n",
       "4    chicago, il  2018-05-08                   19  0.023171"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yesterday_location = weight_location[len(weight_location)-2]\n",
    "df_yesterday_location = df_yesterday_location.rename(columns={'frequency':'frequency_yesterday'})\n",
    "df_yesterday_location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>frequency_today</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albuquerque, nm</td>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>37</td>\n",
       "      <td>0.081140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new york, ny</td>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>28</td>\n",
       "      <td>0.061404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sterling, va</td>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>24</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mclean, va</td>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>24</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>charlotte, nc</td>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>17</td>\n",
       "      <td>0.037281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          location        date  frequency_today    weight\n",
       "0  albuquerque, nm  2018-05-09               37  0.081140\n",
       "1     new york, ny  2018-05-09               28  0.061404\n",
       "2     sterling, va  2018-05-09               24  0.052632\n",
       "3       mclean, va  2018-05-09               24  0.052632\n",
       "4    charlotte, nc  2018-05-09               17  0.037281"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_today_location = weight_location[len(weight_location)-1]\n",
    "df_today_location = df_today_location.rename(columns={'frequency':'frequency_today'})\n",
    "df_today_location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all the table together so we can have a consitent view\n",
    "merged_location = grouped_location.merge(df_today_location, on='location', how='left')\n",
    "merged_location = merged_location.merge(df_yesterday_location, on='location',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the dataframe by average weight so later we can just keep the 40 most frequent skills\n",
    "merged_location = merged_location.sort_values(by='average_weight', ascending=False)\n",
    "merged_location = merged_location.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_location = merged_location.rename(columns={'date_x':'date_today', 'weight_x':'weight_today','weight_y':\n",
    "                                            'weight_yesterday','date_y':'date_yesterday'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_location['today_trend'] = merged_location['weight_today']- merged_location['weight_yesterday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_location = merged_location.drop(['frequency_today','frequency_yesterday'],axis=1)\n",
    "merged_location['today_trend'] = round(merged_location['today_trend'],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\medSr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(merged_location)):\n",
    "    if merged_location['today_trend'].iloc[i] == -0.0:\n",
    "        merged_location['today_trend'].iloc[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_location = merged_location.reset_index()\n",
    "merged_location = merged_location.drop(['index','level_0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_location[:39].to_sql('today_trend_location', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displayed list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>average_weight</th>\n",
       "      <th>date_today</th>\n",
       "      <th>weight_today</th>\n",
       "      <th>date_yesterday</th>\n",
       "      <th>weight_yesterday</th>\n",
       "      <th>today_trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new york, ny</td>\n",
       "      <td>0.043174</td>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>0.061404</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>0.051220</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>charlotte, nc</td>\n",
       "      <td>0.041015</td>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>0.037281</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>0.041463</td>\n",
       "      <td>-0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atlanta, ga</td>\n",
       "      <td>0.026730</td>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>0.010965</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>0.028049</td>\n",
       "      <td>-0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chicago, il</td>\n",
       "      <td>0.025708</td>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>0.023171</td>\n",
       "      <td>-0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>austin, tx</td>\n",
       "      <td>0.019725</td>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>2018-05-08</td>\n",
       "      <td>0.030488</td>\n",
       "      <td>-0.022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        location  average_weight  date_today  weight_today date_yesterday  \\\n",
       "0   new york, ny        0.043174  2018-05-09      0.061404     2018-05-08   \n",
       "1  charlotte, nc        0.041015  2018-05-09      0.037281     2018-05-08   \n",
       "2    atlanta, ga        0.026730  2018-05-09      0.010965     2018-05-08   \n",
       "3    chicago, il        0.025708  2018-05-09      0.017544     2018-05-08   \n",
       "4     austin, tx        0.019725  2018-05-09      0.008772     2018-05-08   \n",
       "\n",
       "   weight_yesterday  today_trend  \n",
       "0          0.051220        0.010  \n",
       "1          0.041463       -0.004  \n",
       "2          0.028049       -0.017  \n",
       "3          0.023171       -0.006  \n",
       "4          0.030488       -0.022  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_location[:39].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Salaries Processing\n",
    "- In the last section of this Notebook, we would like to determine which cities pays the most to their data scientists. \n",
    "- We will calculate this through a period of time, and will then display the top 40 cities that pays the most according to **today's** data. \n",
    "- We will be calculating the average salary of each city in the U.S and plot the result in a chart-line as we did for the last two sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `process_salary()` is a function that will help us separate the good data from the bad ones. The overall idea is to make sure that we are differentiating between the hourly, monthly and annual salary. Unfortunately, Dice allow employers only to enter manually the salary data.\n",
    "\n",
    "We will be taking the following hypothesis to filter the output:\n",
    "\n",
    "1) if salary in the column salary is less than 100, we will multiply the value by 1000 because some of the values are followed by K.\n",
    "\n",
    "2) if salary is `<=` than 900, we will multiply the value by 1000 as the value is likely to be followed by K.\n",
    "\n",
    "3) if salary is `<` than 40k, we will presume that the value is likely to be a short-term contract, so we will be eliminating those values.\n",
    "\n",
    "4) if the salary is `>=` 300000, we will presume that there is a mistake in those value, we will be eliminating those values as well from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_salary(data):\n",
    "    df = data.copy()\n",
    "    df= df.reset_index()\n",
    "    df['salary'] = df['salary'].str.extract('(\\d+)').dropna().astype(int)\n",
    "    df = df[df['salary'] > 50]\n",
    "    arr = []\n",
    "    for i in range(len(df)):\n",
    "        salary = df.iloc[i]['salary']\n",
    "        if salary <= 900:\n",
    "            salary = salary * 1000\n",
    "        if salary >= 300000:\n",
    "            salary = np.nan\n",
    "        arr.append(salary)\n",
    "    df['salary'] = arr\n",
    "    df = df.dropna()\n",
    "    df['salary'] = df.salary.astype(int)\n",
    "    return df[['date_posted','location','salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\medSr\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: currently extract(expand=None) means expand=False (return Index/Series/DataFrame) but in a future version of pandas this will be changed to expand=True (return DataFrame)\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "salary_process = [process_salary(split[i]) for i in range(len(split))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All salaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_salary = pd.concat(salary_process).reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process the salary table that holds all data\n",
    "salary_table = concat_salary.groupby(['date_posted','location'])['salary'].mean()\n",
    "salary_table = salary_table.reset_index()\n",
    "#convert the date columnf into string data type\n",
    "salary_table['date_posted'] = salary_table['date_posted'].dt.strftime('%Y-%m-%d')\n",
    "salary_table['salary'] = salary_table['salary'].apply(lambda x : int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_table.to_sql('salary_table',con=engine, if_exists='replace' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 40 paying cities TODAY:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_posted</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>North Las Vegas, NV</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>Carson, CA</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>Cincinnati, OH</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>Kennesaw, GA</td>\n",
       "      <td>75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>Irving, TX</td>\n",
       "      <td>55000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_posted             location  salary\n",
       "32  2018-05-09  North Las Vegas, NV   70000\n",
       "39  2018-05-09           Carson, CA   70000\n",
       "43  2018-05-09       Cincinnati, OH   80000\n",
       "50  2018-05-09         Kennesaw, GA   75000\n",
       "71  2018-05-09           Irving, TX   55000"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today_salary = salary_process[len(salary_process)-1]\n",
    "yesterday_salary= salary_process[len(salary_process)-2]\n",
    "today_salary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_salary= today_salary.groupby(['date_posted','location'])['salary'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_data = salary_table.merge(today_salary, on='location', how='left')\n",
    "today_data = today_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_data = today_data.groupby('location')['salary_y'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_data = today_data.sort_values('salary_y',ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_data['salary_y'] = round(today_data['salary_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_data = today_data.rename({'salary_y':'today_salary'},axis=1)\n",
    "today_data = today_data.reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_data.to_sql('average_salary',con=engine, if_exists='replace' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>today_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>145451.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>111667.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decatur, GA</td>\n",
       "      <td>106914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wilmington, DE</td>\n",
       "      <td>102073.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Westlake, TX</td>\n",
       "      <td>90000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         location  today_salary\n",
       "0     Houston, TX      145451.0\n",
       "1    New York, NY      111667.0\n",
       "2     Decatur, GA      106914.0\n",
       "3  Wilmington, DE      102073.0\n",
       "4    Westlake, TX       90000.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web Site template : https://themeforest.net/item/infinity-responsive-web-app-kit/16230780"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
